{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOAQ9L219EfZ98saPXsZwHF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTl0leJWaaEa","executionInfo":{"status":"ok","timestamp":1746146086717,"user_tz":420,"elapsed":10888,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"acf5ce38-aba1-4858-c8a9-3424e39ab48d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n","Collecting findspark\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n","Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=d34e4bbddfdc4d1d3b94871eb4c345b467cf4ad556026d3dfce6d99637270dcb\n","  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n","Successfully built wget\n","Installing collected packages: wget, findspark\n","Successfully installed findspark-2.0.1 wget-3.2\n"]}],"source":["# Installing required packages\n","\n","!pip install wget pyspark  findspark"]},{"cell_type":"markdown","source":["Initiate the Spark Session"],"metadata":{"id":"2ru5DyY3azol"}},{"cell_type":"code","source":["import findspark\n","\n","findspark.init()"],"metadata":{"id":"whR3bLegavbV","executionInfo":{"status":"ok","timestamp":1746146111068,"user_tz":420,"elapsed":412,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the SparkContext.\n","\n","from pyspark import SparkContext, SparkConf\n","\n","from pyspark.sql import SparkSession"],"metadata":{"id":"iEPXxaGka8-a","executionInfo":{"status":"ok","timestamp":1746146171889,"user_tz":420,"elapsed":42,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Creating a SparkContext object\n","\n","sc = SparkContext.getOrCreate()\n","\n","# Creating a Spark Session\n","\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark DataFrames basic example\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()"],"metadata":{"id":"DXqrgIe0bHiA","executionInfo":{"status":"ok","timestamp":1746146207870,"user_tz":420,"elapsed":8112,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#download dataset using wget\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/dataset1.csv\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/dataset2.csv\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gtbCiBNObm8k","executionInfo":{"status":"ok","timestamp":1746147065566,"user_tz":420,"elapsed":518,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"130cce52-de2e-4591-c314-a23a129a4692"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-05-02 00:51:05--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/dataset1.csv\n","Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n","Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4115 (4.0K) [text/csv]\n","Saving to: ‘dataset1.csv’\n","\n","dataset1.csv        100%[===================>]   4.02K  --.-KB/s    in 0s      \n","\n","2025-05-02 00:51:05 (1.23 GB/s) - ‘dataset1.csv’ saved [4115/4115]\n","\n","--2025-05-02 00:51:05--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/dataset2.csv\n","Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n","Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2688 (2.6K) [text/csv]\n","Saving to: ‘dataset2.csv’\n","\n","dataset2.csv        100%[===================>]   2.62K  --.-KB/s    in 0s      \n","\n","2025-05-02 00:51:05 (825 MB/s) - ‘dataset2.csv’ saved [2688/2688]\n","\n"]}]},{"cell_type":"code","source":["# load the data into a pyspark dataframe\n","df1 = spark.read.format(\"csv\") \\\n","    .option(\"header\", \"true\") \\\n","    .option(\"inferSchema\", \"true\") \\\n","    .load(\"dataset1.csv\")\n","df2 = spark.read.format(\"csv\") \\\n","    .option(\"header\", \"true\") \\\n","    .option(\"inferSchema\", \"true\") \\\n","    .load(\"dataset2.csv\")"],"metadata":{"id":"WzCIUsS-ehDM","executionInfo":{"status":"ok","timestamp":1746147803450,"user_tz":420,"elapsed":2196,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#print the schema of df1 and df2\n","\n","df1.printSchema()\n","df2.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U70XOCl_fCTF","executionInfo":{"status":"ok","timestamp":1746147810396,"user_tz":420,"elapsed":9,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"5372726a-8a2e-4f50-8a56-86bcf6ccf068"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- customer_id: integer (nullable = true)\n"," |-- date_column: string (nullable = true)\n"," |-- amount: integer (nullable = true)\n"," |-- description: string (nullable = true)\n"," |-- location: string (nullable = true)\n","\n","root\n"," |-- customer_id: integer (nullable = true)\n"," |-- transaction_date: string (nullable = true)\n"," |-- value: integer (nullable = true)\n"," |-- notes: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["## Task 3: Add a new column to each dataframe"],"metadata":{"id":"6ho1x_YdfFKG"}},{"source":["from pyspark.sql.functions import year, quarter, to_date\n","\n","# Add year column to df1\n","df1 = df1.withColumn('year', year(to_date('date_column','M/d/yyyy'))) # Changed the date format to 'M/d/yyyy' to accommodate single-digit months\n","\n","# Add quarter column to df2\n","df2 = df2.withColumn('quarter', quarter(to_date('transaction_date','M/d/yyyy'))) # Changed the date format to 'M/d/yyyy' to accommodate single-digit months\n","\n","# Optional: display results\n","df1.show(5)\n","df2.show(5)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJF6IeTIiKJn","executionInfo":{"status":"ok","timestamp":1746148066934,"user_tz":420,"elapsed":601,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"bf0c154b-2fc6-442f-e930-006d0530208d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-----------+------+-----------+--------+----+\n","|customer_id|date_column|amount|description|location|year|\n","+-----------+-----------+------+-----------+--------+----+\n","|          1|   1/1/2022|  5000| Purchase A| Store A|2022|\n","|          2|  15/2/2022|  1200| Purchase B| Store B|NULL|\n","|          3|  20/3/2022|   800| Purchase C| Store C|NULL|\n","|          4|  10/4/2022|  3000| Purchase D| Store D|2022|\n","|          5|   5/5/2022|  6000| Purchase E| Store E|2022|\n","+-----------+-----------+------+-----------+--------+----+\n","only showing top 5 rows\n","\n","+-----------+----------------+-----+------+-------+\n","|customer_id|transaction_date|value| notes|quarter|\n","+-----------+----------------+-----+------+-------+\n","|          1|        1/1/2022| 1500|Note 1|      1|\n","|          2|       15/2/2022| 2000|Note 2|   NULL|\n","|          3|       20/3/2022| 1000|Note 3|   NULL|\n","|          4|       10/4/2022| 2500|Note 4|      4|\n","|          5|        5/5/2022| 1800|Note 5|      2|\n","+-----------+----------------+-----+------+-------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","source":["# Rename 'amount' to 'transaction_amount' in df1\n","df1 = df1.withColumnRenamed(\"amount\", \"transaction_amount\")\n","\n","# Rename 'value' to 'transaction_value' in df2\n","df2 = df2.withColumnRenamed(\"value\", \"transaction_value\")"],"metadata":{"id":"eqAk7rfii5Ra","executionInfo":{"status":"ok","timestamp":1746148243491,"user_tz":420,"elapsed":34,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Drop 'description' and 'location' from df1\n","df1 = df1.drop(\"description\", \"location\")\n","\n","# Drop 'notes' from df2\n","df2 = df2.drop(\"notes\")"],"metadata":{"id":"VeUIvTFIjMND","executionInfo":{"status":"ok","timestamp":1746148317971,"user_tz":420,"elapsed":80,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Inner join based on 'customer_id'\n","joined_df = df1.join(df2, on='customer_id', how='inner')\n","\n","# Show the result\n","joined_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ztL80WBjfmT","executionInfo":{"status":"ok","timestamp":1746148396550,"user_tz":420,"elapsed":1424,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"45caab1a-90c5-4be2-fe58-b650ecd6cece"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-----------+------------------+----+----------------+-----------------+-------+\n","|customer_id|date_column|transaction_amount|year|transaction_date|transaction_value|quarter|\n","+-----------+-----------+------------------+----+----------------+-----------------+-------+\n","|          1|   1/1/2022|              5000|2022|        1/1/2022|             1500|      1|\n","|          2|  15/2/2022|              1200|NULL|       15/2/2022|             2000|   NULL|\n","|          3|  20/3/2022|               800|NULL|       20/3/2022|             1000|   NULL|\n","|          4|  10/4/2022|              3000|2022|       10/4/2022|             2500|      4|\n","|          5|   5/5/2022|              6000|2022|        5/5/2022|             1800|      2|\n","|          6|  10/6/2022|              4500|2022|       10/6/2022|             1200|      4|\n","|          7|  15/7/2022|               200|NULL|       15/7/2022|              700|   NULL|\n","|          8|  20/8/2022|              3500|NULL|       20/8/2022|             3000|   NULL|\n","|          9|  25/9/2022|               700|NULL|       25/9/2022|              600|   NULL|\n","|         10| 30/10/2022|              1800|NULL|      30/10/2022|             1200|   NULL|\n","|         11|  5/11/2022|              2200|2022|       5/11/2022|             1500|      2|\n","|         12| 10/12/2022|               900|2022|      10/12/2022|              800|      4|\n","|         13|  15/1/2023|              4800|NULL|       15/1/2023|             2000|   NULL|\n","|         14|  20/2/2023|               300|NULL|       20/2/2023|              700|   NULL|\n","|         15|  25/3/2023|              4200|NULL|       25/3/2023|             1800|   NULL|\n","|         16|  30/4/2023|              2600|NULL|       30/4/2023|             1000|   NULL|\n","|         17|   5/5/2023|               700|2023|        5/5/2023|              400|      2|\n","|         18|  10/6/2023|              1500|2023|       10/6/2023|             1500|      4|\n","|         19|  15/7/2023|              3200|NULL|       15/7/2023|             3000|   NULL|\n","|         20|  20/8/2023|              1000|NULL|       20/8/2023|              600|   NULL|\n","+-----------+-----------+------------------+----+----------------+-----------------+-------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["# Filter rows where transaction_amount > 1000\n","filtered_df = joined_df.filter(\"transaction_amount > 1000\")\n","\n","# Show result\n","filtered_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQljDydHkQKp","executionInfo":{"status":"ok","timestamp":1746148594915,"user_tz":420,"elapsed":1064,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"db198af6-5577-424c-fca5-d81a1879ef58"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-----------+------------------+----+----------------+-----------------+-------+\n","|customer_id|date_column|transaction_amount|year|transaction_date|transaction_value|quarter|\n","+-----------+-----------+------------------+----+----------------+-----------------+-------+\n","|          1|   1/1/2022|              5000|2022|        1/1/2022|             1500|      1|\n","|          2|  15/2/2022|              1200|NULL|       15/2/2022|             2000|   NULL|\n","|          4|  10/4/2022|              3000|2022|       10/4/2022|             2500|      4|\n","|          5|   5/5/2022|              6000|2022|        5/5/2022|             1800|      2|\n","|          6|  10/6/2022|              4500|2022|       10/6/2022|             1200|      4|\n","|          8|  20/8/2022|              3500|NULL|       20/8/2022|             3000|   NULL|\n","|         10| 30/10/2022|              1800|NULL|      30/10/2022|             1200|   NULL|\n","|         11|  5/11/2022|              2200|2022|       5/11/2022|             1500|      2|\n","|         13|  15/1/2023|              4800|NULL|       15/1/2023|             2000|   NULL|\n","|         15|  25/3/2023|              4200|NULL|       25/3/2023|             1800|   NULL|\n","|         16|  30/4/2023|              2600|NULL|       30/4/2023|             1000|   NULL|\n","|         18|  10/6/2023|              1500|2023|       10/6/2023|             1500|      4|\n","|         19|  15/7/2023|              3200|NULL|       15/7/2023|             3000|   NULL|\n","|         21|  25/9/2023|              5500|NULL|       25/9/2023|             2500|   NULL|\n","|         22| 30/10/2023|              1200|NULL|      30/10/2023|              700|   NULL|\n","|         24| 10/12/2023|              2400|2023|      10/12/2023|             1200|      4|\n","|         25|  15/1/2024|              1800|NULL|       15/1/2024|              800|   NULL|\n","|         27|  25/3/2024|              4200|NULL|       25/3/2024|             1800|   NULL|\n","|         28|  30/4/2024|              2600|NULL|       30/4/2024|             1000|   NULL|\n","|         30|  10/6/2024|              1500|2024|       10/6/2024|             1500|      4|\n","+-----------+-----------+------------------+----+----------------+-----------------+-------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.functions import sum as _sum # import sum function and rename\n","\n","# Group by customer_id and calculate total transaction_amount\n","total_per_customer = filtered_df.groupBy(\"customer_id\").agg(\n","    _sum(filtered_df[\"transaction_amount\"].cast(\"double\")).alias(\"total_transaction_amount\") # Cast 'transaction_amount' to numeric type (double)\n",")\n","\n","# Show result\n","total_per_customer.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkx-oxWckUnC","executionInfo":{"status":"ok","timestamp":1746148824958,"user_tz":420,"elapsed":2391,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"971607ed-56b1-44ee-8639-73efb686a436"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+------------------------+\n","|customer_id|total_transaction_amount|\n","+-----------+------------------------+\n","|         31|                  3200.0|\n","|         85|                  1800.0|\n","|         78|                  1500.0|\n","|         34|                  1200.0|\n","|         81|                  5500.0|\n","|         28|                  2600.0|\n","|         76|                  2600.0|\n","|         27|                  4200.0|\n","|         91|                  3200.0|\n","|         22|                  1200.0|\n","|         93|                  5500.0|\n","|          1|                  5000.0|\n","|         52|                  2600.0|\n","|         13|                  4800.0|\n","|          6|                  4500.0|\n","|         16|                  2600.0|\n","|         40|                  2600.0|\n","|         94|                  1200.0|\n","|         57|                  5500.0|\n","|         54|                  1500.0|\n","+-----------+------------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Task 9: Write the result to a Hive table"],"metadata":{"id":"SwK2OIcwlQn6"}},{"cell_type":"code","source":["# Write to Hive table named customer_totals\n","total_per_customer.write.mode(\"overwrite\").saveAsTable(\"customer_totals\")\n"],"metadata":{"id":"kFS1tcxHlao1","executionInfo":{"status":"ok","timestamp":1746169683759,"user_tz":420,"elapsed":1261,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Task 10: Write the filtered data to HDFS"],"metadata":{"id":"SQGW4Y5A04Rz"}},{"cell_type":"code","source":["#Write filtered_df to HDFS in parquet format file filtered_data\n","\n","filtered_df.write.mode(\"overwrite\").parquet(\"filtered_data.parquet\")"],"metadata":{"id":"hqnqL3VG098P","executionInfo":{"status":"ok","timestamp":1746169825522,"user_tz":420,"elapsed":1218,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## Task 11: Add a new column based on a condition"],"metadata":{"id":"uQOK54nc1XMN"}},{"cell_type":"code","source":["from pyspark.sql.functions import when, col # Import when and col\n","\n","# Add high_value column to indicate if transaction_amount > 5000\n","df1 = df1.withColumn(\n","    \"high_value\",\n","    when(col(\"transaction_amount\") > 5000, \"Yes\").otherwise(\"No\")\n",")\n","\n","# Show result\n","df1.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDRUJh1I1dLu","executionInfo":{"status":"ok","timestamp":1746170046422,"user_tz":420,"elapsed":1801,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"0a214eba-522c-4c3e-f2bb-33a6a825230f"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-----------+------------------+----+----------+\n","|customer_id|date_column|transaction_amount|year|high_value|\n","+-----------+-----------+------------------+----+----------+\n","|          1|   1/1/2022|              5000|2022|        No|\n","|          2|  15/2/2022|              1200|NULL|        No|\n","|          3|  20/3/2022|               800|NULL|        No|\n","|          4|  10/4/2022|              3000|2022|        No|\n","|          5|   5/5/2022|              6000|2022|       Yes|\n","|          6|  10/6/2022|              4500|2022|        No|\n","|          7|  15/7/2022|               200|NULL|        No|\n","|          8|  20/8/2022|              3500|NULL|        No|\n","|          9|  25/9/2022|               700|NULL|        No|\n","|         10| 30/10/2022|              1800|NULL|        No|\n","|         11|  5/11/2022|              2200|2022|        No|\n","|         12| 10/12/2022|               900|2022|        No|\n","|         13|  15/1/2023|              4800|NULL|        No|\n","|         14|  20/2/2023|               300|NULL|        No|\n","|         15|  25/3/2023|              4200|NULL|        No|\n","|         16|  30/4/2023|              2600|NULL|        No|\n","|         17|   5/5/2023|               700|2023|        No|\n","|         18|  10/6/2023|              1500|2023|        No|\n","|         19|  15/7/2023|              3200|NULL|        No|\n","|         20|  20/8/2023|              1000|NULL|        No|\n","+-----------+-----------+------------------+----+----------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Task 12: Calculate the average transaction value per quarter"],"metadata":{"id":"ps3U3xee2P9R"}},{"cell_type":"code","source":["from pyspark.sql.functions import avg\n","\n","# Group by 'quarter' and calculate the average of 'transaction_value'\n","average_value_per_quarter = df2.groupBy(\"quarter\").agg(\n","    avg(\"transaction_value\").alias(\"avg_trans_val\")\n",")\n","\n","# Show result\n","average_value_per_quarter.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPvfblNM2YWc","executionInfo":{"status":"ok","timestamp":1746170182705,"user_tz":420,"elapsed":1717,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"bfe5ab06-a99a-4032-8141-07bcd1977467"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------------------+\n","|quarter|     avg_trans_val|\n","+-------+------------------+\n","|   NULL|1357.5757575757575|\n","|      1|            1500.0|\n","|      4|1376.4705882352941|\n","|      2|            556.25|\n","+-------+------------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 13: Write the result to a Hive table"],"metadata":{"id":"Xt8ApiBq272O"}},{"cell_type":"code","source":["# Write to Hive table named quarterly_averages\n","average_value_per_quarter.write.mode(\"overwrite\").saveAsTable(\"quarterly_averages\")\n"],"metadata":{"id":"T-4T1KYL235D","executionInfo":{"status":"ok","timestamp":1746170365580,"user_tz":420,"elapsed":944,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["## Task 14: Calculate the total transaction value per year"],"metadata":{"id":"KNzQPHAJ4M6l"}},{"cell_type":"code","source":["total_value_per_year = df1.groupBy('year').agg(\n","    _sum(col(\"transaction_amount\").cast(\"double\")).alias(\"total_transaction_val\")  # Cast 'transaction_amount' to numeric type (double or integer)\n",")\n","\n","\n","# show the total transaction value for each year in df1.\n","total_value_per_year.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5X0L5Uay2xEb","executionInfo":{"status":"ok","timestamp":1746170713555,"user_tz":420,"elapsed":955,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"1725437f-1d29-4f71-a1c4-97b571025b1c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---------------------+\n","|year|total_transaction_val|\n","+----+---------------------+\n","|2025|               5300.0|\n","|2027|               5300.0|\n","|2023|               5300.0|\n","|2022|              21600.0|\n","|NULL|             162900.0|\n","|2026|               5300.0|\n","|2029|               5300.0|\n","|2028|               5300.0|\n","|2024|               5300.0|\n","+----+---------------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 15: Write the result to HDFS"],"metadata":{"id":"06QW_dMr4_S_"}},{"cell_type":"code","source":["total_value_per_year.write.mode(\"overwrite\").csv(\"total_value_per_year.csv\")"],"metadata":{"id":"XkR_gWkc5JAp","executionInfo":{"status":"ok","timestamp":1746170890609,"user_tz":420,"elapsed":910,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":31,"outputs":[]}]}