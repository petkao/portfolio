{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeWP6wu77dba7mJCyh8E7e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Prerequisites"],"metadata":{"id":"o0rNsSHx6AlI"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZ2JG5cQ5_j3","executionInfo":{"status":"ok","timestamp":1746224823823,"user_tz":420,"elapsed":4452,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"a1deedb9-2a4a-418e-b41d-ab5e5fa89894"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n","Collecting findspark\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n","Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=5846fd9c6f1555020becb8615645d0a2538a48a8acac25df704d90eb257e7cea\n","  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n","Successfully built wget\n","Installing collected packages: wget, findspark\n","Successfully installed findspark-2.0.1 wget-3.2\n"]}],"source":["# Installing required packages\n","\n","!pip install pysparkâ€¯ findspark wget"]},{"cell_type":"code","source":["import findspark\n","\n","findspark.init()"],"metadata":{"id":"qc2xTBgh6UwH","executionInfo":{"status":"ok","timestamp":1746224828838,"user_tz":420,"elapsed":640,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the SparkContext.\n","\n","from pyspark import SparkContext, SparkConf\n","\n","from pyspark.sql import SparkSession"],"metadata":{"id":"g_e-MtZL6X2D","executionInfo":{"status":"ok","timestamp":1746224832758,"user_tz":420,"elapsed":11,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Creating a SparkContext object\n","\n","sc = SparkContext.getOrCreate()\n","\n","# Creating a SparkSession\n","\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark DataFrames basic example\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()"],"metadata":{"id":"RXcomasv6eFb","executionInfo":{"status":"ok","timestamp":1746224845537,"user_tz":420,"elapsed":8929,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Download the CSV data first into a local `employees.csv` file\n","import wget\n","wget.download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/data/employees.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"N436xSDG60ce","executionInfo":{"status":"ok","timestamp":1746224853074,"user_tz":420,"elapsed":214,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"a1f6b767-d605-4a3b-d9c3-69b7b4d19175"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'employees.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Task 1: Generate aSpark DataFrame from the CSV data"],"metadata":{"id":"U1O6DbXw7hDu"}},{"cell_type":"code","source":["# load the data into a pyspark dataframe\n","employees_df = spark.read.format(\"csv\") \\\n","    .option(\"header\", \"true\") \\\n","    .option(\"inferSchema\", \"true\") \\\n","    .load(\"employees.csv\")"],"metadata":{"id":"BmTQQKkW7fz9","executionInfo":{"status":"ok","timestamp":1746224868360,"user_tz":420,"elapsed":10343,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Task 2: Define a chema for the data"],"metadata":{"id":"o0HtMky18fXU"}},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n","\n","schema = StructType([\n","    StructField(\"Emp_No\", IntegerType(), True),\n","    StructField(\"Emp_Name\", StringType(), True),\n","    StructField(\"Salary\", IntegerType(), True),\n","    StructField(\"Age\", IntegerType(), True),\n","    StructField(\"Department\", StringType(), True)\n","])\n","\n","df = spark.read.csv(\"employees.csv\", schema=schema, header=True)\n"],"metadata":{"id":"4dJlAhv69Nz4","executionInfo":{"status":"ok","timestamp":1746224874725,"user_tz":420,"elapsed":64,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xP114STJ-msA","executionInfo":{"status":"ok","timestamp":1746224879248,"user_tz":420,"elapsed":4,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"43b9f231-1bd6-4206-c3f7-fe60150d7a23"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Emp_No: integer (nullable = true)\n"," |-- Emp_Name: string (nullable = true)\n"," |-- Salary: integer (nullable = true)\n"," |-- Age: integer (nullable = true)\n"," |-- Department: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["Task 3: Display schema of DataFrame"],"metadata":{"id":"MaNj-F7I9PWO"}},{"cell_type":"code","source":["employees_df.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGajee6z8WEc","executionInfo":{"status":"ok","timestamp":1746224884275,"user_tz":420,"elapsed":8,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"ec35e021-f4e6-4d77-ea1c-f321793729d3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Emp_No: integer (nullable = true)\n"," |-- Emp_Name: string (nullable = true)\n"," |-- Salary: integer (nullable = true)\n"," |-- Age: integer (nullable = true)\n"," |-- Department: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["## Task 4: Create a temporary view"],"metadata":{"id":"9srhtpXhGb5P"}},{"cell_type":"code","source":["employees_df.createOrReplaceTempView(\"employees\")"],"metadata":{"id":"WFde5agvGa1g","executionInfo":{"status":"ok","timestamp":1746224888299,"user_tz":420,"elapsed":44,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Task 5: Execute an SQL query"],"metadata":{"id":"AqHNWBBIHXzz"}},{"cell_type":"code","source":["age_temp_df = spark.sql(\"\"\"\n","    SELECT *\n","    FROM employees\n","    WHERE Age > 30\n","\"\"\")\n","\n","age_temp_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AILsLoOWHgb8","executionInfo":{"status":"ok","timestamp":1746225528808,"user_tz":420,"elapsed":783,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"03e69a05-3b2d-4ac3-f2d4-0b939383bcb7"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+-----------+------+---+----------+\n","|Emp_No|   Emp_Name|Salary|Age|Department|\n","+------+-----------+------+---+----------+\n","|   199|    Douglas|  2600| 34|     Sales|\n","|   200|   Jennifer|  4400| 36| Marketing|\n","|   201|    Michael| 13000| 32|        IT|\n","|   202|        Pat|  6000| 39|        HR|\n","|   203|      Susan|  6500| 36| Marketing|\n","|   205|    Shelley| 12008| 33|   Finance|\n","|   206|    William|  8300| 37|        IT|\n","|   100|     Steven| 24000| 39|        IT|\n","|   102|        Lex| 17000| 37| Marketing|\n","|   103|  Alexander|  9000| 39| Marketing|\n","|   104|      Bruce|  6000| 38|        IT|\n","|   105|      David|  4800| 39|        IT|\n","|   106|      Valli|  4800| 38|     Sales|\n","|   107|      Diana|  4200| 35|     Sales|\n","|   109|     Daniel|  9000| 35|        HR|\n","|   110|       John|  8200| 31| Marketing|\n","|   111|     Ismael|  7700| 32|        IT|\n","|   112|Jose Manuel|  7800| 34|        HR|\n","|   113|       Luis|  6900| 34|     Sales|\n","|   116|     Shelli|  2900| 37|   Finance|\n","+------+-----------+------+---+----------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Task 6:  Calculate Average Salary by Deparment"],"metadata":{"id":"VS-GjIb8IMYd"}},{"cell_type":"code","source":["avg_salary_df = spark.sql(\"\"\"\n","    SELECT department, AVG(salary) AS avg_salary\n","    FROM employees\n","    GROUP BY department\n","\"\"\")\n","\n","avg_salary_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3_oGkWlIi4v","executionInfo":{"status":"ok","timestamp":1746225534048,"user_tz":420,"elapsed":1745,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"81aba384-8298-40c4-ae00-7c2afc8f8c66"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-----------------+\n","|department|       avg_salary|\n","+----------+-----------------+\n","|     Sales|5492.923076923077|\n","|        HR|           5837.5|\n","|   Finance|           5730.8|\n","| Marketing|6633.333333333333|\n","|        IT|           7400.0|\n","+----------+-----------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 7: Filter and Display IT Department Employees"],"metadata":{"id":"HCbttgtPJ7EZ"}},{"cell_type":"code","source":["filtered_temp_df = spark.sql(\"\"\"\n","    SELECT *\n","    FROM employees\n","    WHERE department = \"IT\"\n","\"\"\")\n","\n","filtered_temp_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFKcDI3GKDVK","executionInfo":{"status":"ok","timestamp":1746225831568,"user_tz":420,"elapsed":288,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"957f4090-f8d5-4ab3-9ee8-e10a0159d4ec"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+--------+------+---+----------+\n","|Emp_No|Emp_Name|Salary|Age|Department|\n","+------+--------+------+---+----------+\n","|   198|  Donald|  2600| 29|        IT|\n","|   201| Michael| 13000| 32|        IT|\n","|   206| William|  8300| 37|        IT|\n","|   100|  Steven| 24000| 39|        IT|\n","|   104|   Bruce|  6000| 38|        IT|\n","|   105|   David|  4800| 39|        IT|\n","|   111|  Ismael|  7700| 32|        IT|\n","|   129|   Laura|  3300| 38|        IT|\n","|   132|      TJ|  2100| 34|        IT|\n","|   136|   Hazel|  2200| 29|        IT|\n","+------+--------+------+---+----------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 8: Add 10% Bonus to Salaries"],"metadata":{"id":"1e2nGA0jLokn"}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n","\n","# Add the SalaryAfterBonus column with 10% bonus\n","employees_with_bonus = employees_df.withColumn(\"SalaryAfterBonus\", col(\"salary\") * 1.10)\n","\n","# Display the updated DataFrame\n","employees_with_bonus.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHOzeR01LnOI","executionInfo":{"status":"ok","timestamp":1746226065644,"user_tz":420,"elapsed":692,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"ff04bfb9-8832-4ca1-aa4e-dcbe05595938"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+---------+------+---+----------+------------------+\n","|Emp_No| Emp_Name|Salary|Age|Department|  SalaryAfterBonus|\n","+------+---------+------+---+----------+------------------+\n","|   198|   Donald|  2600| 29|        IT|2860.0000000000005|\n","|   199|  Douglas|  2600| 34|     Sales|2860.0000000000005|\n","|   200| Jennifer|  4400| 36| Marketing|            4840.0|\n","|   201|  Michael| 13000| 32|        IT|14300.000000000002|\n","|   202|      Pat|  6000| 39|        HR| 6600.000000000001|\n","|   203|    Susan|  6500| 36| Marketing| 7150.000000000001|\n","|   204|  Hermann| 10000| 29|   Finance|           11000.0|\n","|   205|  Shelley| 12008| 33|   Finance|13208.800000000001|\n","|   206|  William|  8300| 37|        IT|            9130.0|\n","|   100|   Steven| 24000| 39|        IT|26400.000000000004|\n","|   101|    Neena| 17000| 27|     Sales|           18700.0|\n","|   102|      Lex| 17000| 37| Marketing|           18700.0|\n","|   103|Alexander|  9000| 39| Marketing|            9900.0|\n","|   104|    Bruce|  6000| 38|        IT| 6600.000000000001|\n","|   105|    David|  4800| 39|        IT|            5280.0|\n","|   106|    Valli|  4800| 38|     Sales|            5280.0|\n","|   107|    Diana|  4200| 35|     Sales|            4620.0|\n","|   108|    Nancy| 12008| 28|     Sales|13208.800000000001|\n","|   109|   Daniel|  9000| 35|        HR|            9900.0|\n","|   110|     John|  8200| 31| Marketing|            9020.0|\n","+------+---------+------+---+----------+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Task: Find Maximum Salary by Age"],"metadata":{"id":"1t-8GOh1L6yZ"}},{"cell_type":"code","source":["from pyspark.sql.functions import max\n","\n","# Group data by age and calculate the maximum salary for each age group\n","max_salary_df = spark.sql(\"\"\"\n","    SELECT age, max(salary) AS max_salary\n","    FROM employees\n","    GROUP BY age\n","\"\"\")\n","\n","max_salary_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F0SWW3tWMBNl","executionInfo":{"status":"ok","timestamp":1746226294362,"user_tz":420,"elapsed":685,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"fa9bae1f-d8e7-4ccc-ef34-6724b13de9cb"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+----------+\n","|age|max_salary|\n","+---+----------+\n","| 31|      8200|\n","| 34|      7800|\n","| 28|     12008|\n","| 27|     17000|\n","| 26|      3600|\n","| 37|     17000|\n","| 35|      9000|\n","| 39|     24000|\n","| 38|      6000|\n","| 29|     10000|\n","| 32|     13000|\n","| 33|     12008|\n","| 30|      8000|\n","| 36|      7900|\n","+---+----------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 10: Self-Join on Employee Data"],"metadata":{"id":"SJWtyzFWMtXe"}},{"cell_type":"code","source":["# Alias the original DataFrame\n","emp1 = employees_df.alias(\"emp1\")\n","emp2 = employees_df.alias(\"emp2\")\n","\n","# Perform self-join on the \"Emp_No\" column\n","joined_df = emp1.join(emp2, emp1[\"Emp_No\"] == emp2[\"Emp_No\"])\n","\n","# Display the result\n","joined_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFonw0s4Mzze","executionInfo":{"status":"ok","timestamp":1746226422790,"user_tz":420,"elapsed":955,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"83545baa-882a-4515-d7b1-bf09eea9b0c2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+---------+------+---+----------+------+---------+------+---+----------+\n","|Emp_No| Emp_Name|Salary|Age|Department|Emp_No| Emp_Name|Salary|Age|Department|\n","+------+---------+------+---+----------+------+---------+------+---+----------+\n","|   198|   Donald|  2600| 29|        IT|   198|   Donald|  2600| 29|        IT|\n","|   199|  Douglas|  2600| 34|     Sales|   199|  Douglas|  2600| 34|     Sales|\n","|   200| Jennifer|  4400| 36| Marketing|   200| Jennifer|  4400| 36| Marketing|\n","|   201|  Michael| 13000| 32|        IT|   201|  Michael| 13000| 32|        IT|\n","|   202|      Pat|  6000| 39|        HR|   202|      Pat|  6000| 39|        HR|\n","|   203|    Susan|  6500| 36| Marketing|   203|    Susan|  6500| 36| Marketing|\n","|   204|  Hermann| 10000| 29|   Finance|   204|  Hermann| 10000| 29|   Finance|\n","|   205|  Shelley| 12008| 33|   Finance|   205|  Shelley| 12008| 33|   Finance|\n","|   206|  William|  8300| 37|        IT|   206|  William|  8300| 37|        IT|\n","|   100|   Steven| 24000| 39|        IT|   100|   Steven| 24000| 39|        IT|\n","|   101|    Neena| 17000| 27|     Sales|   101|    Neena| 17000| 27|     Sales|\n","|   102|      Lex| 17000| 37| Marketing|   102|      Lex| 17000| 37| Marketing|\n","|   103|Alexander|  9000| 39| Marketing|   103|Alexander|  9000| 39| Marketing|\n","|   104|    Bruce|  6000| 38|        IT|   104|    Bruce|  6000| 38|        IT|\n","|   105|    David|  4800| 39|        IT|   105|    David|  4800| 39|        IT|\n","|   106|    Valli|  4800| 38|     Sales|   106|    Valli|  4800| 38|     Sales|\n","|   107|    Diana|  4200| 35|     Sales|   107|    Diana|  4200| 35|     Sales|\n","|   108|    Nancy| 12008| 28|     Sales|   108|    Nancy| 12008| 28|     Sales|\n","|   109|   Daniel|  9000| 35|        HR|   109|   Daniel|  9000| 35|        HR|\n","|   110|     John|  8200| 31| Marketing|   110|     John|  8200| 31| Marketing|\n","+------+---------+------+---+----------+------+---------+------+---+----------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Task 11: Calculate the average age of employees using the built-in aggregation function. Display the result."],"metadata":{"id":"bFI4g2gUNWzS"}},{"cell_type":"code","source":["from pyspark.sql.functions import avg\n","\n","# Calculate average age\n","average_age_df = employees_df.select(avg(\"age\").alias(\"Average_Age\"))\n","\n","# Display the result\n","average_age_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_1QbGkgNVdM","executionInfo":{"status":"ok","timestamp":1746226602718,"user_tz":420,"elapsed":401,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"da420b8d-c59c-4d15-8754-27ace29b34df"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+\n","|Average_Age|\n","+-----------+\n","|      33.56|\n","+-----------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 12: Calculate Total Salary by Deparment"],"metadata":{"id":"5c18wP5CN6-M"}},{"cell_type":"code","source":["from pyspark.sql.functions import sum\n","\n","# Group by department and calculate total salary\n","total_salary_per_dept = employees_df.groupBy(\"department\").agg(sum(\"salary\").alias(\"Total_Salary\"))\n","\n","# Display the result\n","total_salary_per_dept.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lT-i0XOQOBRA","executionInfo":{"status":"ok","timestamp":1746226718997,"user_tz":420,"elapsed":708,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"54018597-e93e-482f-ecb5-72bd5f034068"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+\n","|department|Total_Salary|\n","+----------+------------+\n","|     Sales|       71408|\n","|        HR|       46700|\n","|   Finance|       57308|\n","| Marketing|       59700|\n","|        IT|       74000|\n","+----------+------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 13: Sort Data by Age and Salary"],"metadata":{"id":"_3294ulPOYY7"}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n","\n","# Sort by age (ascending) and salary (descending)\n","sorted_df = employees_df.orderBy(col(\"age\").asc(), col(\"salary\").desc())\n","\n","# Display the sorted DataFrame\n","sorted_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jn7XYKpjOdbW","executionInfo":{"status":"ok","timestamp":1746226828945,"user_tz":420,"elapsed":538,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"71e2e007-3ca4-4e2b-d498-d7010132f0d8"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+---------+------+---+----------+\n","|Emp_No| Emp_Name|Salary|Age|Department|\n","+------+---------+------+---+----------+\n","|   137|   Renske|  3600| 26| Marketing|\n","|   101|    Neena| 17000| 27|     Sales|\n","|   114|      Den| 11000| 27|   Finance|\n","|   108|    Nancy| 12008| 28|     Sales|\n","|   130|    Mozhe|  2800| 28| Marketing|\n","|   126|    Irene|  2700| 28|        HR|\n","|   204|  Hermann| 10000| 29|   Finance|\n","|   115|Alexander|  3100| 29|   Finance|\n","|   134|  Michael|  2900| 29|     Sales|\n","|   198|   Donald|  2600| 29|        IT|\n","|   140|   Joshua|  2500| 29|   Finance|\n","|   136|    Hazel|  2200| 29|        IT|\n","|   120|  Matthew|  8000| 30|        HR|\n","|   110|     John|  8200| 31| Marketing|\n","|   127|    James|  2400| 31|        HR|\n","|   201|  Michael| 13000| 32|        IT|\n","|   111|   Ismael|  7700| 32|        IT|\n","|   119|    Karen|  2500| 32|   Finance|\n","|   205|  Shelley| 12008| 33|   Finance|\n","|   124|    Kevin|  5800| 33| Marketing|\n","+------+---------+------+---+----------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Task 14: Count Employees in Each Department"],"metadata":{"id":"Qak7SbF9O0-X"}},{"cell_type":"code","source":["from pyspark.sql.functions import count\n","\n","# Calculate the number of employees in each department. Display the result.\n","count_emp_df = spark.sql(\"\"\"\n","    SELECT department, count(Emp_No)\n","    FROM employees\n","    GROUP BY department\n","\"\"\")\n","\n","count_emp_df.show()\n","\n","# Group by department and count employees\n","employee_count_per_dept = employees_df.groupBy(\"department\").agg(count(\"*\").alias(\"Employee_Count\"))\n","\n","# Display the result\n","employee_count_per_dept.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ILHBIkCO6iY","executionInfo":{"status":"ok","timestamp":1746227345440,"user_tz":420,"elapsed":1279,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"2b6bfb6b-e510-4b15-84f1-afb18768c117"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-------------+\n","|department|count(Emp_No)|\n","+----------+-------------+\n","|     Sales|           13|\n","|        HR|            8|\n","|   Finance|           10|\n","| Marketing|            9|\n","|        IT|           10|\n","+----------+-------------+\n","\n","+----------+--------------+\n","|department|Employee_Count|\n","+----------+--------------+\n","|     Sales|            13|\n","|        HR|             8|\n","|   Finance|            10|\n","| Marketing|             9|\n","|        IT|            10|\n","+----------+--------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Task 15: Filter Employees with the letter o in the Nme"],"metadata":{"id":"5OOw0iEwQtoQ"}},{"cell_type":"code","source":["# Apply a filter to select records where the employee's name contains the letter 'o'\n","filtered_emp_df = employees_df.filter(col(\"Emp_Name\").like(\"%o%\"))\n","filtered_emp_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d46os24EQ2bt","executionInfo":{"status":"ok","timestamp":1746227617578,"user_tz":420,"elapsed":614,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"a6dedbbc-eea5-4879-8fae-27ab759249ec"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+-----------+------+---+----------+\n","|Emp_No|   Emp_Name|Salary|Age|Department|\n","+------+-----------+------+---+----------+\n","|   198|     Donald|  2600| 29|        IT|\n","|   199|    Douglas|  2600| 34|     Sales|\n","|   110|       John|  8200| 31| Marketing|\n","|   112|Jose Manuel|  7800| 34|        HR|\n","|   130|      Mozhe|  2800| 28| Marketing|\n","|   133|      Jason|  3300| 38|     Sales|\n","|   139|       John|  2700| 36|     Sales|\n","|   140|     Joshua|  2500| 29|   Finance|\n","+------+-----------+------+---+----------+\n","\n"]}]}]}